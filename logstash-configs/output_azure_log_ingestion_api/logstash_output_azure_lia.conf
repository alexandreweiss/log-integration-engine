input {
    udp {
        port => 5000
        type => syslog
    }
    tcp {
        port => 5000
        type => syslog
    }
}

#microseg logs
filter {
    if [type] == "syslog" and "avxperfmon" not in [tags] {
        grok {
            id => "microseg"
            patterns_dir => ["/usr/share/logstash/patterns"]
            break_on_match => true
            add_tag => [
                "microseg",
                "ebpf" # to differentiate between mitm and ebpf
            ]
            remove_tag => ["_grokparsefailure"]
            match => {
                "message" => [
                    # Example log
                    # <133>May 14 03:46:16 GW-aws-usw1-0a330200-gw-54.219.57.58 syslog 2022-05-14T03:46:10.257442+00:00 GW-aws-usw1-0a330200-gw-54.219.57.58 /usr/local/bin/avx-gw-state-sync[5432]: 2022/05/14 03:46:10 AviatrixGwMicrosegPacket: POLICY=96438983-a98c-9938-fcbc-73f72e83f089 SRC_MAC=06:ef:2f:7d:10:83 DST_MAC=06:97:38:9c:5a:df IP_SZ=60 SRC_IP=10.4.221.148 DST_IP=10.235.240.155 PROTO=TCP SRC_PORT=42948 DST_PORT=2000 DATA=0x
                    "^<%{NUMBER}>%{SPACE}(%{MONTH} +%{MONTHDAY} +%{TIME} +%{HOSTNAME}-%{IP} syslog )?%{SYSLOG_TIMESTAMP:date} +GW-%{HOSTNAME:gw_hostname}-%{IP} +%{PATH}(\[%{NUMBER}\]:)? +%{YEAR}\/%{SPACE}%{MONTHNUM}\/%{SPACE}%{MONTHDAY} +%{TIME} +AviatrixGwMicrosegPacket: POLICY=%{UUID:uuid} SRC_MAC=%{MAC:src_mac} DST_MAC=%{MAC:dst_mac} IP_SZ=%{NUMBER} SRC_IP=%{IP:src_ip} DST_IP=%{IP:dst_ip} PROTO=%{WORD:proto} SRC_PORT=%{NUMBER:src_port} DST_PORT=%{NUMBER:dst_port} DATA=%{GREEDYDATA} ACT=%{WORD:action} ENFORCED=%{WORD:enforced}",
                    "^<%{NUMBER}>%{SPACE}(%{MONTH} +%{MONTHDAY} +%{TIME} +%{HOSTNAME}-%{IP} syslog )?%{SYSLOG_TIMESTAMP:date} +GW-%{HOSTNAME:gw_hostname}-%{IP} +%{PATH}(\[%{NUMBER}\]:)? +%{YEAR}\/%{SPACE}%{MONTHNUM}\/%{SPACE}%{MONTHDAY} +%{TIME} +AviatrixGwMicrosegPacket: POLICY=%{UUID:uuid} SRC_MAC=%{MAC:src_mac} DST_MAC=%{MAC:dst_mac} IP_SZ=%{NUMBER} SRC_IP=%{IP:src_ip} DST_IP=%{IP:dst_ip} PROTO=%{WORD:proto} SRC_PORT=%{NUMBER:src_port} DST_PORT=%{NUMBER:dst_port} DATA=%{GREEDYDATA}"
                ]
            }
            remove_field => [
                "message",
                "event",
                "@version",
                "type",
                "host"
            ]
        }
    }
}

# throttle l4 microseg logs
# throttle l4 microseg logs
filter {
        if "microseg" in [tags] and "mitm" not in [tags] {
                # This config will throttle the logs for each connection to
                #  max 2 logs/minute (src -> dest and src <- dest).
                # Theoretically, 1k concurrent connections would generate up to 2k logs/minute,
                #  and 120k logs/hour
                # Scale testing shows ~3.7mb for 74k logs
                throttle {
                        id => "microseg-throttle"
                        key => "%{uuid}%{src_ip}%{dest_ip}%{src_port}%{dst_port}%{proto}"
                        max_age => 120
                        period => "60"
                        after_count => 1
                        add_tag => "throttled"
                }
        }
}

filter {
	if "throttled" in [tags] {
		drop {
                        id => "microseg-throttled"
                }
	}
}

filter {
        # grok match and json parse seem to be outputting all fields
        #  as strings, so here we convert the common microseg fields to their proper types
        if "microseg" in [tags] {
                mutate {
                        id => "microseg-field-conversion"
                        convert => {
                                "src_port" => "integer"
                                "dst_port" => "integer"
                                "enforced" => "boolean"
                        }
                }
        }
}


# suricata
filter {
        if [type] == "syslog" {
                grok {
                        id => "suricata"
                        patterns_dir => ["/usr/share/logstash/patterns"]
                        break_on_match => true
                        add_tag => ["suricata"]
                        match => {
                                "message" => [
                                        "^<%{NUMBER}>%{SPACE}(%{MONTH} +%{MONTHDAY} +%{TIME} +%{HOSTNAME}-%{IP} syslog )?%{SYSLOG_TIMESTAMP:date} +%{HOSTNAME:gw_hostname}-%{IP} suricata(\[%{NUMBER}\]:)? %{GREEDYDATA:suricataData}"
                                ]
                        }
                }
                if "suricata" in [tags] and [suricataData] =~ "\A\{.+\}\z" {
                        json {
                                id => "suricata-data"
                                skip_on_invalid_json => true
                                source => "suricataData"
                                target => "suricataDataJson"
                        }
                }
        }
}

#set date
filter {
        date {
                id => "date-to-timestamp"
                # The timestamp format MMM dd HH:mm:ss is used by the new syslog format
                # i.e. May 14 03:46:16
                match => [ "date", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSSSSS", "MMM dd HH:mm:ss" ]
                target => "@timestamp"
                remove_field => [ "date" ]
        }
}

filter {
    if "suricata" in [tags] {
        mutate {
            id => "suricata4dcr-cleanup"
            remove_field => ["message", "suricataData", "gw_hostname", "host", "port", "type","event"]
        }
        
        # Add TimeGenerated field and flatten suricataDataJson
        ruby {
            code => "
                if event.get('suricataDataJson')
                    # Add TimeGenerated field
                    event.set('TimeGenerated', event.get('@timestamp'))
                    
                    # Flatten suricataDataJson into the event
                    event.get('suricataDataJson').each { |k, v| event.set(k, v) }
                    event.remove('suricataDataJson')
                end
            "
        }
    }
}

output {
    if "suricata" in [tags] {
        microsoft-sentinel-log-analytics-logstash-output-plugin {
            # create_sample_file => true
            # sample_file_path => "./"
            client_app_Id=> "${client_app_id}"
            client_app_secret => "${client_app_secret}"
            tenant_id => "${tenant_id}"
            data_collection_endpoint => "${data_collection_endpoint}"
            dcr_immutable_id => "${azure_dcr_suricata_id}"
            dcr_stream_name => "${azure_stream_suricata}"
            azure_cloud => "${azure_cloud}"
        }
    }
    else if "microseg" in [tags] {
        microsoft-sentinel-log-analytics-logstash-output-plugin {
            # create_sample_file => true
            # sample_file_path => "./"
            client_app_Id=> "${client_app_id}"
            client_app_secret => "${client_app_secret}"
            tenant_id => "${tenant_id}"
            data_collection_endpoint => "${data_collection_endpoint}"
            dcr_immutable_id => "${azure_dcr_microseg_id}"
            dcr_stream_name => "${azure_stream_microseg}"
            azure_cloud => "${azure_cloud}"
        }
    }
}